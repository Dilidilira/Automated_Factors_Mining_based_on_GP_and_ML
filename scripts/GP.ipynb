{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import random\n",
    "import pickle\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from deap import base, creator, tools, gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478ebbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "\n",
    "# ---------- 基础工具 ----------\n",
    "def _to_arr(x):\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "def _win_from(x, default=10, lo=2, hi=60):\n",
    "    \"\"\"把第三个参数/窗口参数变成标量窗口长度。\"\"\"\n",
    "    x = _to_arr(x)\n",
    "    try:\n",
    "        n = int(np.nanmedian(np.abs(x)))\n",
    "    except Exception:\n",
    "        n = int(abs(float(x)))\n",
    "    if not np.isfinite(n):\n",
    "        n = default\n",
    "    return min(max(n, lo), hi)\n",
    "\n",
    "def safe_truediv(a, b):\n",
    "    a, b = _to_arr(a), _to_arr(b)\n",
    "    out = np.zeros_like(a, dtype=float)\n",
    "    m = np.abs(b) > EPS\n",
    "    out[m] = a[m] / b[m]\n",
    "    return out\n",
    "\n",
    "# ---------- 时序延迟/差分 ----------\n",
    "def _delay(x, k):\n",
    "    x = _to_arr(x)\n",
    "    if x.size == 0: return x\n",
    "    y = np.empty_like(x)\n",
    "    y[:k] = np.nan\n",
    "    y[k:] = x[:-k]\n",
    "    return y\n",
    "\n",
    "def gp_delay_1(x):  return _delay(x, 1)\n",
    "def gp_delay_2(x):  return _delay(x, 2)\n",
    "def gp_delay_3(x):  return _delay(x, 3)\n",
    "def gp_delay_4(x):  return _delay(x, 4)\n",
    "def gp_delay_5(x):  return _delay(x, 5)\n",
    "def gp_delay_6(x):  return _delay(x, 6)\n",
    "def gp_delay_7(x):  return _delay(x, 7)\n",
    "def gp_delay_8(x):  return _delay(x, 8)\n",
    "\n",
    "def gp_delta(x):\n",
    "    x = _to_arr(x)\n",
    "    y = np.empty_like(x)\n",
    "    y[:] = np.nan\n",
    "    y[1:] = x[1:] - x[:-1]\n",
    "    return y\n",
    "\n",
    "def gp_signedpower(x):\n",
    "    x = _to_arr(x)\n",
    "    return np.sign(x) * np.power(np.abs(x) + EPS, 0.5)  # 可按需改幂次\n",
    "\n",
    "# ---------- 平滑/衰减 ----------\n",
    "def _ema(x, span):\n",
    "    s = pd.Series(_to_arr(x))\n",
    "    return s.ewm(span=int(span), min_periods=1, adjust=False).mean().values\n",
    "\n",
    "def gp_decay_05(x): return _ema(x, 5)\n",
    "def gp_decay_10(x): return _ema(x, 10)\n",
    "def gp_decay_20(x): return _ema(x, 20)\n",
    "\n",
    "# ---------- 逻辑/比较 ----------\n",
    "def gp_and(a, b): return ((_to_arr(a) > 0) & (_to_arr(b) > 0)).astype(float)\n",
    "def gp_or(a, b):  return ((_to_arr(a) > 0) | (_to_arr(b) > 0)).astype(float)\n",
    "def gp_lt(a, b):  return (_to_arr(a) < _to_arr(b)).astype(float)\n",
    "def gp_gt(a, b):  return (_to_arr(a) > _to_arr(b)).astype(float)\n",
    "\n",
    "def gp_if(cond, x, y):\n",
    "    c = _to_arr(cond)\n",
    "    x, y = _to_arr(x), _to_arr(y)\n",
    "    return np.where(c > 0, x, y)\n",
    "\n",
    "def gp_if_then_else(a, b, x, y):\n",
    "    aa, bb = _to_arr(a), _to_arr(b)\n",
    "    x, y = _to_arr(x), _to_arr(y)\n",
    "    return np.where(aa > bb, x, y)\n",
    "\n",
    "# ---------- 聚合/统计 ----------\n",
    "def gp_max(a, b): return np.maximum(_to_arr(a), _to_arr(b))\n",
    "def gp_min(a, b): return np.minimum(_to_arr(a), _to_arr(b))\n",
    "def gp_log(x):    return np.log(np.abs(_to_arr(x)) + EPS)\n",
    "def gp_abs(x):    return np.abs(_to_arr(x))\n",
    "def gp_vneg(x):   return -_to_arr(x)\n",
    "def gp_sign(x):   return np.sign(_to_arr(x))\n",
    "\n",
    "def _rolling(x, win, func):\n",
    "    s = pd.Series(_to_arr(x))\n",
    "    return s.rolling(win, min_periods=1).apply(func, raw=True).values\n",
    "\n",
    "def gp_stddev_05(x): return pd.Series(_to_arr(x)).rolling(5, 1).std().values\n",
    "def gp_stddev_10(x): return pd.Series(_to_arr(x)).rolling(10, 1).std().values\n",
    "def gp_stddev_15(x): return pd.Series(_to_arr(x)).rolling(15, 1).std().values\n",
    "\n",
    "def gp_prod_05(x):   return pd.Series(_to_arr(x)).rolling(5, 1).apply(lambda v: np.prod(v), raw=True).values\n",
    "def gp_prod_10(x):   return pd.Series(_to_arr(x)).rolling(10,1).apply(lambda v: np.prod(v), raw=True).values\n",
    "def gp_prod_20(x):   return pd.Series(_to_arr(x)).rolling(20,1).apply(lambda v: np.prod(v), raw=True).values\n",
    "\n",
    "def gp_wma(x, w, n):\n",
    "    x, w = _to_arr(x), _to_arr(w)\n",
    "    win = _win_from(n, default=10)\n",
    "    xs, ws = pd.Series(x), pd.Series(np.abs(w) + EPS)\n",
    "    num = (xs * ws).rolling(win, min_periods=1).sum()\n",
    "    den = ws.rolling(win, min_periods=1).sum()\n",
    "    return (num / den).values\n",
    "\n",
    "def gp_cov_05(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(5, 1).cov(b).values\n",
    "\n",
    "def gp_cov_10(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(10, 1).cov(b).values\n",
    "\n",
    "def gp_cov_20(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(20, 1).cov(b).values\n",
    "\n",
    "def gp_corr_05(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(5, 1).corr(b).values\n",
    "\n",
    "def gp_corr_10(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(10, 1).corr(b).values\n",
    "\n",
    "def gp_corr_20(a, b):\n",
    "    a, b = pd.Series(_to_arr(a)), pd.Series(_to_arr(b))\n",
    "    return a.rolling(20, 1).corr(b).values\n",
    "\n",
    "def gp_mean2(a, b):                 return np.nanmean(np.vstack([_to_arr(a), _to_arr(b)]), axis=0)\n",
    "def gp_mean3(a, b, c):              return np.nanmean(np.vstack([_to_arr(a), _to_arr(b), _to_arr(c)]), axis=0)\n",
    "def gp_mean4(a, b, c, d):           return np.nanmean(np.vstack([_to_arr(a), _to_arr(b), _to_arr(c), _to_arr(d)]), axis=0)\n",
    "def gp_mean5(a, b, c, d, e):        return np.nanmean(np.vstack([_to_arr(a), _to_arr(b), _to_arr(c), _to_arr(d), _to_arr(e)]), axis=0)\n",
    "def gp_mean6(a, b, c, d, e, f):     return np.nanmean(np.vstack([_to_arr(a), _to_arr(b), _to_arr(c), _to_arr(d), _to_arr(e), _to_arr(f)]), axis=0)\n",
    "def gp_mean7(a, b, c, d, e, f, g):  return np.nanmean(np.vstack([_to_arr(a), _to_arr(b), _to_arr(c), _to_arr(d), _to_arr(e), _to_arr(f), _to_arr(g)]), axis=0)\n",
    "\n",
    "def gp_clear_by_cond(x, y, cond):\n",
    "    \"\"\"cond>0 取 y，否则取 x（一个通用的按条件清洗/替换）。\"\"\"\n",
    "    return np.where(_to_arr(cond) > 0, _to_arr(y), _to_arr(x))\n",
    "\n",
    "def rank_x1(x, w1, w2, w3):\n",
    "    \"\"\"把 x 做一个滚动百分位 rank（窗口来自 w1）；这是通用实现，和你私有版可能略有差异。\"\"\"\n",
    "    n = _win_from(w1, default=10)\n",
    "    s = pd.Series(_to_arr(x))\n",
    "    def _pct_rank(a):\n",
    "        ser = pd.Series(a)\n",
    "        return ser.rank(pct=True).iloc[-1]\n",
    "    return s.rolling(n, min_periods=1).apply(lambda v: _pct_rank(v), raw=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb4a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共计19个因子\n",
      "保留19个优秀因子：['open_interest', 'alpha054', 'alpha013', 'amount', 'alpha002', 'alpha191', 'alpha135', 'alpha022', 'volume', 'alpha096', 'alpha162', 'alpha038', 'alpha165', 'alpha049', 'alpha166', 'alpha066', 'alpha161', 'open', 'alpha183']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "d:\\Anaconda\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 配置全局参数\n",
    "# =========================\n",
    "# # \"\"\"\n",
    "# N_GENERATIONS = 7\n",
    "# POP_SIZE = 2000\n",
    "# MUT_PB, MUT_Point, CXPB = 0.05, 0.4, 0.5  # 子树变异率/点变异率/交叉率\n",
    "# NUM_HOF = 200  # 名人堂：精英个体进入名人堂的数目\n",
    "# hall_of_fame = tools.HallOfFame(NUM_HOF)\n",
    "# NUM_ELITE = 200  # 精英策略：精英个体跳过自然选择的数目\n",
    "# tournament_size = 5  # 锦标赛压力\n",
    "# # \"\"\"\n",
    "\n",
    "# 试运行版\n",
    "\n",
    "N_GENERATIONS = 2\n",
    "POP_SIZE = 10\n",
    "MUT_PB, MUT_Point, CXPB = 0.05, 0.4, 0.5\n",
    "NUM_HOF = 1\n",
    "hall_of_fame = tools.HallOfFame(NUM_HOF)\n",
    "NUM_ELITE = 1\n",
    "tournament_size = 5\n",
    "\n",
    "\n",
    "# 配置文件提取储存路径\n",
    "Ver = 'V6'\n",
    "path01 = 'Trees/Factors_selected.csv'  # 选取因子代码提取路径\n",
    "path02 = 'GP/V6/'                     # 种群储存路径\n",
    "path03 = 'Trees/alphas191_data_V2.csv'  # 因子数据提取路径\n",
    "path04 = 'GP/V6/HOF.csv'              # 名人堂结果存储路径\n",
    "\n",
    "# =========================\n",
    "# 定义因子\n",
    "# =========================\n",
    "# factors = pd.read_csv(path01)\n",
    "# new_factors = factors['Alpha_Index'].iloc[20:28].to_list()  # 新引入因子\n",
    "\n",
    "# 加入优秀因子（前代高重要性因子/量价数据）\n",
    "exellent = [\n",
    "    'open_interest', 'alpha054', 'alpha013', 'amount', 'alpha002', 'alpha191',\n",
    "    'alpha135', 'alpha022', 'volume', 'alpha096', 'alpha162', 'alpha038',\n",
    "    'alpha165', 'alpha049', 'alpha166', 'alpha066', 'alpha161', 'open', 'alpha183'\n",
    "]\n",
    "factors_selected = exellent #+ new_factors\n",
    "FACTOR_COUNT = len(factors_selected)\n",
    "\n",
    "print(f\"共计{FACTOR_COUNT}个因子\")\n",
    "print(f\"保留{len(exellent)}个优秀因子：{exellent}\")\n",
    "#print(f\"新引入{len(new_factors)}个新因子：{new_factors}\")\n",
    "\n",
    "# =========================\n",
    "# 创建 DEAP 的基本结构\n",
    "# =========================\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0, -1.0, -1.0))  # 多目标：IC均值绝对值最大化，IC标准差最小化，空值最小化, 复杂度最小化\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMulti)   # 定义个体是符号树\n",
    "\n",
    "# 注册遗传算法工具\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# 定义 Primitive Set（用于定义操作符 primitive 和变量 terminal）\n",
    "pset = gp.PrimitiveSet(\"MAIN\", FACTOR_COUNT)\n",
    "for factor in factors_selected:\n",
    "    pset.renameArguments(**{f'ARG{factors_selected.index(factor)}': factor})\n",
    "\n",
    "# —— 基础算子与常量（自定义原语函数请确保在环境中可用） ——\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(safe_truediv, 2)  # 除法（需自定义：安全除法）\n",
    "pset.addPrimitive(np.sin, 1)\n",
    "pset.addPrimitive(np.cos, 1)\n",
    "pset.addPrimitive(np.tan, 1)\n",
    "pset.addEphemeralConstant(\"rand\", partial(np.random.uniform, 0, 20.0))  # 随机常量\n",
    "# pset.addEphemeralConstant(\"rand_int\", partial(random.randint, 1, 10))  # 随机整数\n",
    "\n",
    "# —— 你的时序与统计原语（需保证已实现） ——\n",
    "pset.addPrimitive(gp_delay_1, 1)\n",
    "pset.addPrimitive(gp_delay_2, 1)\n",
    "pset.addPrimitive(gp_delay_3, 1)\n",
    "pset.addPrimitive(gp_delay_4, 1)\n",
    "pset.addPrimitive(gp_delay_5, 1)\n",
    "pset.addPrimitive(gp_delay_6, 1)\n",
    "pset.addPrimitive(gp_delay_7, 1)\n",
    "pset.addPrimitive(gp_delay_8, 1)\n",
    "pset.addPrimitive(gp_delta, 1)\n",
    "pset.addPrimitive(gp_signedpower, 1)\n",
    "pset.addPrimitive(gp_decay_05, 1)\n",
    "pset.addPrimitive(gp_decay_10, 1)\n",
    "pset.addPrimitive(gp_decay_20, 1)\n",
    "pset.addPrimitive(gp_and, 2)\n",
    "pset.addPrimitive(gp_or, 2)\n",
    "pset.addPrimitive(gp_lt, 2)\n",
    "pset.addPrimitive(gp_gt, 2)\n",
    "pset.addPrimitive(gp_if, 3)\n",
    "pset.addPrimitive(gp_max, 2)\n",
    "pset.addPrimitive(gp_min, 2)\n",
    "pset.addPrimitive(gp_stddev_05, 1)\n",
    "pset.addPrimitive(gp_stddev_10, 1)\n",
    "pset.addPrimitive(gp_stddev_15, 1)\n",
    "pset.addPrimitive(gp_log, 1)\n",
    "pset.addPrimitive(gp_abs, 1)\n",
    "pset.addPrimitive(gp_prod_05, 1)\n",
    "pset.addPrimitive(gp_prod_10, 1)\n",
    "pset.addPrimitive(gp_prod_20, 1)\n",
    "pset.addPrimitive(gp_wma, 3)\n",
    "pset.addPrimitive(gp_vneg, 1)\n",
    "pset.addPrimitive(gp_sign, 1)\n",
    "pset.addPrimitive(gp_cov_05, 2)\n",
    "pset.addPrimitive(gp_cov_10, 2)\n",
    "pset.addPrimitive(gp_cov_20, 2)\n",
    "pset.addPrimitive(gp_corr_05, 2)\n",
    "pset.addPrimitive(gp_corr_10, 2)\n",
    "pset.addPrimitive(gp_corr_20, 2)\n",
    "pset.addPrimitive(gp_mean2, 2)\n",
    "pset.addPrimitive(gp_mean3, 3)\n",
    "pset.addPrimitive(gp_mean4, 4)\n",
    "pset.addPrimitive(gp_mean5, 5)\n",
    "pset.addPrimitive(gp_mean6, 6)\n",
    "pset.addPrimitive(gp_mean7, 7)\n",
    "pset.addPrimitive(gp_clear_by_cond, 3)\n",
    "pset.addPrimitive(gp_if_then_else, 4)\n",
    "pset.addPrimitive(rank_x1, 4)\n",
    "\n",
    "# =========================\n",
    "# 适应度评估（总适应度，多合约合并）\n",
    "# =========================\n",
    "def evaluate_individual(individual, func, datasets):\n",
    "    \"\"\"\n",
    "    评估全局个体适应度（多个合约的数据）。\n",
    "    :param individual: 当前的符号树（GP 表达式）。\n",
    "    :param func: 编译后的符号树公式。\n",
    "    :param datasets: 包含多个合约的训练数据 [(X1, y1), (X2, y2), ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 保存每个合约计算出的新因子值和对应的收益率，用于计算IC\n",
    "        new_factors_dict = {}\n",
    "        returns_dict = {}\n",
    "\n",
    "        # 将符号树编译为可执行函数\n",
    "        compiled_func = func(individual)\n",
    "\n",
    "        # 检查公式树是否包含选定因子\n",
    "        tree_str = str(individual)\n",
    "        factors_in_func = 0\n",
    "        for factor in factors_selected:\n",
    "            if factor in tree_str:\n",
    "                factors_in_func += 1\n",
    "        if factors_in_func == 0:  # 惩罚公式中不包含选定因子的因子\n",
    "            return (float(\"-inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\"))\n",
    "\n",
    "        for name, X_train, Y_train in datasets:\n",
    "            X_sample = X_train.values.T\n",
    "            Y_sample = Y_train.values\n",
    "\n",
    "            # compiled_func 接受若干 numpy 数组作为输入\n",
    "            predictions = compiled_func(*X_sample)\n",
    "            new_factors_dict[name] = pd.Series(predictions, index=X_train.index)\n",
    "            returns_dict[name] = pd.Series(Y_sample, index=Y_train.index)\n",
    "\n",
    "        new_factors_df = pd.DataFrame(new_factors_dict)\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "\n",
    "        ic_values = []\n",
    "        nan_count = 0  # 空值计数器\n",
    "        for time in new_factors_df.index:\n",
    "            ic = new_factors_df.loc[time].corr(returns_df.loc[time])\n",
    "            ic = pd.to_numeric(ic, errors='coerce')\n",
    "            if np.isnan(ic):\n",
    "                nan_count += 1\n",
    "            else:\n",
    "                ic_values.append(ic)\n",
    "\n",
    "        # 惩罚过大的空值: 若空值个数超过 1% 则惩罚\n",
    "        threshold = 0.01\n",
    "        if len(new_factors_df) - len(ic_values) >= threshold * len(new_factors_df):\n",
    "            return (float(\"-inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\"))\n",
    "        else:\n",
    "            if np.abs(np.nanmean(ic_values)) < 0.001:  # 惩罚过低的 IC 绝对值\n",
    "                return (float(\"-inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\"))\n",
    "            else:\n",
    "                avg_ic = np.nanmean(ic_values)   # 平均 IC\n",
    "                abs_avr_ic = np.abs(avg_ic)\n",
    "                std_ic = np.nanvar(ic_values)    # 方差（原注释写 ICIR）\n",
    "                complexity = len(individual)     # 个体复杂度\n",
    "                return (abs_avr_ic, std_ic, nan_count, complexity)\n",
    "\n",
    "    except Exception:\n",
    "        # 如果计算错误，返回无穷大作为惩罚\n",
    "        return (float(\"-inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\"))\n",
    "\n",
    "# =========================\n",
    "# 无效个体处理 & 多样性/表现监控\n",
    "# =========================\n",
    "def is_valid(ind):\n",
    "    return ind.fitness.values[0] != float(\"-inf\")\n",
    "\n",
    "def is_valid_and_unique(new_ind, population_set):\n",
    "    if not is_valid(new_ind):\n",
    "        return False\n",
    "    if str(new_ind) in population_set:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def ineffective_processing(population):\n",
    "    \"\"\"\n",
    "    种群无效个体处理：持续生成有效个体来替换种群中无效个体，直到种群中所有个体都有效；\n",
    "    新生成的有效个体需要不同于原始个体以保证多样性\n",
    "    \"\"\"\n",
    "    population_set = set(str(ind) for ind in population if is_valid(ind))\n",
    "    for i, ind in enumerate(population):\n",
    "        if not is_valid(ind):\n",
    "            while True:\n",
    "                new_ind = toolbox.individual()\n",
    "                new_ind.fitness.values = toolbox.evaluate(new_ind)\n",
    "                if is_valid_and_unique(new_ind, population_set):\n",
    "                    population[i] = new_ind\n",
    "                    population_set.add(str(new_ind))\n",
    "                    break\n",
    "    return population\n",
    "\n",
    "def effective_ind(population):\n",
    "    return len([ind for ind in population if ind.fitness.values[0] != float(\"-inf\")]) / len(population)\n",
    "\n",
    "def genotype_diversity(population):\n",
    "    unique_individuals = set(str(ind) for ind in population if ind.fitness.values[0] != float(\"-inf\"))\n",
    "    denom = len([ind for ind in population if ind.fitness.values[0] != float(\"-inf\")])\n",
    "    return len(unique_individuals) / denom if denom > 0 else 0\n",
    "\n",
    "def phenotype_diversity(population):\n",
    "    fitness_values = [ind.fitness.values[0] for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    if len(fitness_values) <= 1:\n",
    "        return 0\n",
    "    return np.std(fitness_values)\n",
    "\n",
    "def hamming_distance(ind1, ind2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(str(ind1), str(ind2)))\n",
    "\n",
    "def average_hamming_distance(population):\n",
    "    total_distance = 0\n",
    "    comparisons = 0\n",
    "    for i in range(len(population)):\n",
    "        for j in range(i + 1, len(population)):\n",
    "            if population[i].fitness.values[0] == float(\"-inf\") or population[j].fitness.values[0] == float(\"-inf\"):\n",
    "                continue\n",
    "            total_distance += hamming_distance(population[i], population[j])\n",
    "            comparisons += 1\n",
    "    return total_distance / comparisons if comparisons > 0 else 0\n",
    "\n",
    "def population_avg_IC(population):\n",
    "    vals = [ind.fitness.values[0] for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    return float(np.mean(vals)) if len(vals) else 0.0\n",
    "\n",
    "def population_avg_IC_std(population):\n",
    "    vals = [ind.fitness.values[1] for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    return float(np.mean(vals)) if len(vals) else 0.0\n",
    "\n",
    "def population_avg_nan_count(population):\n",
    "    vals = [ind.fitness.values[2] for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    return float(np.mean(vals)) if len(vals) else 0.0\n",
    "\n",
    "def population_avg_complexity(population):\n",
    "    vals = [ind.fitness.values[3] for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    return float(np.mean(vals)) if len(vals) else 0.0\n",
    "\n",
    "# =========================\n",
    "# 0-1 标准化 / 反归一化\n",
    "# =========================\n",
    "def normalizing_population(population):\n",
    "    valid = [ind for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "    min_f1 = min(ind.fitness.values[0] for ind in valid)\n",
    "    max_f1 = max(ind.fitness.values[0] for ind in valid)\n",
    "    min_f2 = min(ind.fitness.values[1] for ind in valid)\n",
    "    max_f2 = max(ind.fitness.values[1] for ind in valid)\n",
    "    min_f3 = min(ind.fitness.values[2] for ind in valid)\n",
    "    max_f3 = max(ind.fitness.values[2] for ind in valid)\n",
    "    min_f4 = min(ind.fitness.values[3] for ind in valid)\n",
    "    max_f4 = max(ind.fitness.values[3] for ind in valid)\n",
    "\n",
    "    for ind in population:\n",
    "        f1 = ind.fitness.values[0]\n",
    "        f2 = ind.fitness.values[1]\n",
    "        f3 = ind.fitness.values[2]\n",
    "        f4 = ind.fitness.values[3]\n",
    "        f1_normalized = (f1 - min_f1) / (max_f1 - min_f1) if max_f1 != min_f1 else 1\n",
    "        f2_normalized = (f2 - min_f2) / (max_f2 - min_f2) if max_f2 != min_f2 else 0\n",
    "        f3_normalized = (f3 - min_f3) / (max_f3 - min_f3) if max_f3 != min_f3 else 0\n",
    "        f4_normalized = (f4 - min_f4) / (max_f4 - min_f4) if max_f4 != min_f4 else 0\n",
    "        ind.fitness.values = (f1_normalized, f2_normalized, f3_normalized, f4_normalized)\n",
    "\n",
    "    Recover_Pac = [[min_f1, max_f1], [min_f2, max_f2], [min_f3, max_f3], [min_f4, max_f4]]\n",
    "    return population, Recover_Pac\n",
    "\n",
    "def denormalizing_population(population, Recover_Pac):\n",
    "    out = []\n",
    "    for ind in population:\n",
    "        f1 = ind.fitness.values[0] * (Recover_Pac[0][1] - Recover_Pac[0][0]) + Recover_Pac[0][0]\n",
    "        f2 = ind.fitness.values[1] * (Recover_Pac[1][1] - Recover_Pac[1][0]) + Recover_Pac[1][0]\n",
    "        f3 = ind.fitness.values[2] * (Recover_Pac[2][1] - Recover_Pac[2][0]) + Recover_Pac[2][0]\n",
    "        f4 = ind.fitness.values[3] * (Recover_Pac[3][1] - Recover_Pac[3][0]) + Recover_Pac[3][0]\n",
    "        ind.fitness.values = (f1, f2, f3, f4)\n",
    "        out.append(ind)\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 选择函数（非支配排序 + 锦标赛）\n",
    "# =========================\n",
    "def tournament_selection(population, tournament_size):\n",
    "    # 非支配排序\n",
    "    fronts = tools.sortNondominated(population, len(population), first_front_only=False)\n",
    "\n",
    "    # 高支配层级的个体获得更多参与锦标赛的机会\n",
    "    probabilities = np.zeros(len(population))\n",
    "    for i, front in enumerate(fronts):\n",
    "        prob = 1.0 / (i + 1)\n",
    "        for ind in front:\n",
    "            probabilities[population.index(ind)] = prob\n",
    "    probabilities /= probabilities.sum()  # 归一化\n",
    "\n",
    "    selected_individuals = []\n",
    "    for _ in range(POP_SIZE - NUM_ELITE):  # 种群个数 - 精英个体个数\n",
    "        competitors = random.choices(population, weights=probabilities, k=tournament_size)\n",
    "        best_individual = tools.selNSGA2(competitors, 1)[0]\n",
    "        selected_individuals.append(best_individual)\n",
    "    return selected_individuals\n",
    "\n",
    "# =========================\n",
    "# 因子重要性监控\n",
    "# =========================\n",
    "def factors_importance(offspring, pset):\n",
    "    \"\"\"\n",
    "    因子重要性：自然选择出的个体中因子出现的频率（后代中包含该因子的个体个数/后代总个体数）\n",
    "    \"\"\"\n",
    "    factors_counter = Counter()\n",
    "    for individual in offspring:\n",
    "        factors = []\n",
    "        for node in individual:\n",
    "            if isinstance(node, gp.Terminal) and not isinstance(node, (float, int)):\n",
    "                if node.name[:3] == 'ARG':  # 只提取变量（因子），排除常数\n",
    "                    index = int(node.name[3:])\n",
    "                    renamed_name = pset.arguments[index]\n",
    "                    factors.append(renamed_name)\n",
    "        factors = set(factors)\n",
    "        factors_counter.update(factors)\n",
    "    factors_counter = dict(factors_counter)\n",
    "\n",
    "    total_selections = len(offspring)\n",
    "    factor_probabilities = {factor: count / total_selections for factor, count in factors_counter.items()}\n",
    "    sorted_factors = sorted(factor_probabilities.items(), key=lambda x: x[1], reverse=True)  # 降序\n",
    "\n",
    "    print(\"因子重要性:\")\n",
    "    for factor, prob in sorted_factors:\n",
    "        print(f\"{factor}: {prob:.2%}\")\n",
    "\n",
    "    return factor_probabilities\n",
    "\n",
    "# =========================\n",
    "# 点变异\n",
    "# =========================\n",
    "def point_mutation(individual, pset):\n",
    "    \"\"\"\n",
    "    对个体进行点变异：选择一个随机节点，替换为新节点。\n",
    "    \"\"\"\n",
    "    node = random.randint(0, len(individual) - 1)\n",
    "    # 终端 -> 新终端\n",
    "    if isinstance(individual[node], gp.Terminal):\n",
    "        available_terminals = [t for t in pset.terminals[pset.ret] if isinstance(t, gp.Terminal)]\n",
    "        individual[node] = random.choice(available_terminals)\n",
    "    # 原始操作符 -> 同元数新操作符\n",
    "    elif isinstance(individual[node], gp.Primitive):\n",
    "        available_primitives = [p for p in pset.primitives[pset.ret] if p.arity == individual[node].arity]\n",
    "        individual[node] = random.choice(available_primitives)\n",
    "    return individual\n",
    "\n",
    "# =========================\n",
    "# 名人堂结果整理\n",
    "# =========================\n",
    "def df_HOF(hall_of_fame):\n",
    "    ind_name = []\n",
    "    IC_list = []\n",
    "    IC_std_list = []\n",
    "    ICIR_list = []\n",
    "    nan_list = []\n",
    "    complexity_list = []\n",
    "\n",
    "    for i, ind in enumerate(hall_of_fame):\n",
    "        ind_name.append(str(ind))\n",
    "        IC_list.append(ind.fitness.values[0])\n",
    "        IC_std_list.append(ind.fitness.values[1])\n",
    "        ICIR_list.append(ind.fitness.values[0] / ind.fitness.values[1] if ind.fitness.values[1] != 0 else np.nan)\n",
    "        nan_list.append(ind.fitness.values[2])\n",
    "        complexity_list.append(ind.fitness.values[3])\n",
    "\n",
    "    f_stats = pd.DataFrame({\n",
    "        '个体': ind_name,\n",
    "        'IC绝对值': IC_list,\n",
    "        'IC_std': IC_std_list,\n",
    "        'ICIR': ICIR_list,\n",
    "        '空值个数': nan_list,\n",
    "        '复杂度': complexity_list\n",
    "    })\n",
    "    return f_stats\n",
    "\n",
    "# =========================\n",
    "# 主训练流程\n",
    "# =========================\n",
    "def run_global_training(datasets):\n",
    "    \"\"\"\n",
    "    针对全局数据训练符号树。\n",
    "    :param datasets: [(X1, y1), (X2, y2), ...]，包含所有合约的数据。\n",
    "    :return: 最优个体列表、其适应度、最终种群、名人堂、名人堂因子重要性\n",
    "    \"\"\"\n",
    "    # 初始化种群的方法\n",
    "    toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=6)\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    # 注册遗传函数\n",
    "    toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "    toolbox.register(\"evaluate\", partial(evaluate_individual, func=toolbox.compile, datasets=datasets))\n",
    "    toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", gp.mutUniform, expr=partial(gp.genHalfAndHalf, min_=1, max_=4), pset=pset)  # 子树变异\n",
    "    toolbox.register(\"mutate_point\", point_mutation, pset=pset)  # 点变异\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)  # 锦标赛选择\n",
    "\n",
    "    # 初始化种群\n",
    "    population = toolbox.population(n=POP_SIZE)\n",
    "\n",
    "    # 进化过程\n",
    "    for gen in tqdm.tqdm(range(N_GENERATIONS)):\n",
    "        print(f\"Generation {gen + 1}:\")\n",
    "\n",
    "        # 评估适应度\n",
    "        fitnesses = list(map(toolbox.evaluate, population))\n",
    "        for ind, fit in zip(population, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        if gen == 0:\n",
    "            # 初代种群无效个体处理\n",
    "            print(\"初始种群无效个体处理中...\")\n",
    "            population = ineffective_processing(population)\n",
    "\n",
    "            # 初始种群多样性检测\n",
    "            effective_ind_pct = effective_ind(population)\n",
    "            genotype_diversity_value = genotype_diversity(population)\n",
    "            phenotype_diversity_value = phenotype_diversity(population)\n",
    "            average_hamming_distance_value = average_hamming_distance(population)\n",
    "            avg_ic = population_avg_IC(population)\n",
    "            avg_ic_std = population_avg_IC_std(population)\n",
    "            avg_nan = population_avg_nan_count(population)\n",
    "            avg_complexity = population_avg_complexity(population)\n",
    "            best_individual = tools.selNSGA2(population, 1)[0]\n",
    "\n",
    "            print(\"种群多样性检测：\")\n",
    "            print(f\"初始种群有效个体占比：{effective_ind_pct:.2%}\")\n",
    "            print(f\"初始种群基因型多样性：{genotype_diversity_value:.2%}\")\n",
    "            print(f\"初始种群表型(abs_IC_mean)多样性：{phenotype_diversity_value:.4}\")\n",
    "            print(f\"初始种群平均汉明距离：{average_hamming_distance_value}\")\n",
    "            print(\"种群表现：\")\n",
    "            print(f\"初始种群平均IC：{avg_ic:.2%}\")\n",
    "            print(f\"初始种群平均IC_std：{avg_ic_std:.2%}\")\n",
    "            print(f\"初始种群平均ICIR：{avg_ic / avg_ic_std:.4}\" if avg_ic_std != 0 else \"初始种群平均ICIR：NaN\")\n",
    "            print(f\"初始种群平均空值个数：{avg_nan}\")\n",
    "            print(f\"初始种群平均复杂度：{avg_complexity:.2f}\")\n",
    "            print(\n",
    "                f\"初始种群最优个体 : {best_individual}, \"\n",
    "                f\"IC绝对值: {best_individual.fitness.values[0]:.2%}, \"\n",
    "                f\"IC_std: {best_individual.fitness.values[1]:.2%}, \"\n",
    "                f\"ICIR: {best_individual.fitness.values[0] / best_individual.fitness.values[1]:.4f} \"\n",
    "                if best_individual.fitness.values[1] != 0 else \"ICIR: NaN\"\n",
    "                f\", 空值个数: {best_individual.fitness.values[2]}, \"\n",
    "                f\"复杂度: {best_individual.fitness.values[3]:.2f},\"\n",
    "            )\n",
    "\n",
    "            with open(path02 + f\"{Ver}_gen{gen + 1}.pkl\", 'wb') as file:\n",
    "                pickle.dump(population, file)\n",
    "\n",
    "        else:\n",
    "            # 后续各代统计\n",
    "            effective_ind_pct = effective_ind(population)\n",
    "            genotype_diversity_value = genotype_diversity(population)\n",
    "            phenotype_diversity_value = phenotype_diversity(population)\n",
    "            average_hamming_distance_value = average_hamming_distance(population)\n",
    "            avg_ic = population_avg_IC(population)\n",
    "            avg_ic_std = population_avg_IC_std(population)\n",
    "            avg_nan = population_avg_nan_count(population)\n",
    "            avg_complexity = population_avg_complexity(population)\n",
    "            best_individual = tools.selNSGA2(population, 1)[0]\n",
    "\n",
    "            print(\"种群多样性检测：\")\n",
    "            print(f\"第{gen + 1}代种群有效个体占比：{effective_ind_pct:.2%}\")\n",
    "            print(f\"第{gen + 1}代种群基因型多样性：{genotype_diversity_value:.2%}\")\n",
    "            print(f\"第{gen + 1}代种群表型多样性：{phenotype_diversity_value:.4}\")\n",
    "            print(f\"第{gen + 1}代种群平均汉明距离：{average_hamming_distance_value}\")\n",
    "            print(\"种群表现：\")\n",
    "            print(f\"第{gen + 1}代种群平均IC:{avg_ic:.2%}\")\n",
    "            print(f\"第{gen + 1}代种群平均IC_std:{avg_ic_std:.2%}\")\n",
    "            print(f\"第{gen + 1}代种群平均ICIR:{avg_ic / avg_ic_std:.4}\" if avg_ic_std != 0 else f\"第{gen + 1}代种群平均ICIR: NaN\")\n",
    "            print(f\"第{gen + 1}代种群平均空值个数：{avg_nan}\")\n",
    "            print(f\"第{gen + 1}代种群平均复杂度：{avg_complexity:.2f}\")\n",
    "            print(\n",
    "                f\"第{gen + 1}代种群最优个体 : {best_individual}, \"\n",
    "                f\"IC绝对值: {best_individual.fitness.values[0]:.2%}, \"\n",
    "                f\"IC_std: {best_individual.fitness.values[1]:.2%}, \"\n",
    "                f\"ICIR: {best_individual.fitness.values[0] / best_individual.fitness.values[1]:.4f} \"\n",
    "                if best_individual.fitness.values[1] != 0 else \"ICIR: NaN\"\n",
    "                f\", 空值个数: {best_individual.fitness.values[2]}, \"\n",
    "                f\"复杂度: {best_individual.fitness.values[3]:.2f},\"\n",
    "            )\n",
    "\n",
    "            with open(path02 + f\"{Ver}_gen{gen + 1}.pkl\", 'wb') as file:\n",
    "                pickle.dump(population, file)\n",
    "\n",
    "        # 删除无效个体\n",
    "        population = [ind for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "\n",
    "        # 标准化多目标值\n",
    "        population, Recover_Pac = normalizing_population(population)\n",
    "\n",
    "        # 使用非支配排序将种群分成多个前沿\n",
    "        fronts = tools.sortNondominated(population, len(population), first_front_only=False)\n",
    "        print(f\"有效个体可以被分为{len(fronts)}个非支配前沿\")\n",
    "        for rank, front in enumerate(fronts):\n",
    "            print(f\"第{rank + 1}层非支配层有{len(front)}个个体\")\n",
    "\n",
    "        # 更新 Hall of Fame\n",
    "        best_individuals = []\n",
    "        for front in fronts:\n",
    "            if len(best_individuals) + len(front) > NUM_HOF:\n",
    "                remaining = NUM_HOF - len(best_individuals)\n",
    "                best_individuals.extend(front[:remaining])\n",
    "                break\n",
    "            best_individuals.extend(front)\n",
    "\n",
    "        best_individuals = denormalizing_population(best_individuals, Recover_Pac)\n",
    "        hall_of_fame.update(best_individuals)\n",
    "\n",
    "        print(\"进化阶段开始...\")\n",
    "        # 选择父代：基于非支配排序与锦标赛选择的选择方法\n",
    "        offspring = tournament_selection(population, tournament_size)\n",
    "\n",
    "        # 克隆后代\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # 因子重要性检测\n",
    "        _ = factors_importance(offspring, pset=pset)\n",
    "\n",
    "        # 交叉操作\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):  # 后代两两配对\n",
    "            if np.random.rand() < CXPB:  # CXPB 交叉概率\n",
    "                toolbox.mate(child1, child2)\n",
    "                if hasattr(child1.fitness, \"values\"):\n",
    "                    del child1.fitness.values\n",
    "                if hasattr(child2.fitness, \"values\"):\n",
    "                    del child2.fitness.values\n",
    "\n",
    "        # 变异操作(子树变异和点变异)\n",
    "        for mutant in offspring:\n",
    "            if np.random.rand() < MUT_PB:  # 子树变异概率\n",
    "                toolbox.mutate(mutant)\n",
    "                if hasattr(mutant.fitness, \"values\"):\n",
    "                    del mutant.fitness.values\n",
    "            else:\n",
    "                if np.random.rand() < MUT_Point:\n",
    "                    toolbox.mutate_point(mutant)\n",
    "                    if hasattr(mutant.fitness, \"values\"):\n",
    "                        del mutant.fitness.values\n",
    "\n",
    "        # 精英策略\n",
    "        elites = best_individuals[:NUM_ELITE]\n",
    "        population[:] = offspring + elites  # 更新种群\n",
    "\n",
    "        print(f\"第{gen + 1}代种群进化完毕，正在计算第{gen + 2}代种群统计值...\")\n",
    "\n",
    "    # =========================\n",
    "    # 最终代评估与输出\n",
    "    # =========================\n",
    "    print(f\"第{N_GENERATIONS + 1}代（最终代）适应度计算中...\")\n",
    "\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # 删除无效个体\n",
    "    population = [ind for ind in population if ind.fitness.values[0] != float(\"-inf\")]\n",
    "\n",
    "    # 标准化多目标值\n",
    "    population, Recover_Pac = normalizing_population(population)\n",
    "\n",
    "    # 使用非支配排序将种群分成多个前沿\n",
    "    fronts = tools.sortNondominated(population, len(population), first_front_only=False)\n",
    "    print(f\"有效个体可以被分为{len(fronts)}个非支配前沿\")\n",
    "    for rank, front in enumerate(fronts):\n",
    "        print(f\"第{rank + 1}层非支配层有{len(front)}个个体\")\n",
    "\n",
    "    # 更新 Hall of Fame\n",
    "    best_individuals = []\n",
    "    for front in fronts:\n",
    "        if len(best_individuals) + len(front) > NUM_HOF:\n",
    "            remaining = NUM_HOF - len(best_individuals)\n",
    "            best_individuals.extend(front[:remaining])\n",
    "            break\n",
    "        best_individuals.extend(front)\n",
    "\n",
    "    best_individuals = denormalizing_population(best_individuals, Recover_Pac)\n",
    "    hall_of_fame.update(best_individuals)\n",
    "\n",
    "    best_individuals = hall_of_fame[:NUM_HOF]\n",
    "    # 名人堂因子出现频率检测\n",
    "    hof_importance = factors_importance(best_individuals, pset=pset)\n",
    "\n",
    "    # 打印 Top 结果\n",
    "    if len(best_individuals) > 0:\n",
    "        top = best_individuals[0]\n",
    "        denom = top.fitness.values[1]\n",
    "        icir = (top.fitness.values[0] / denom) if denom != 0 else np.nan\n",
    "\n",
    "    for i, ind in enumerate(best_individuals):\n",
    "        print(\n",
    "            f\"Top {i + 1} 个体 : {ind}, \"\n",
    "            f\"IC绝对值: {ind.fitness.values[0]}, \"\n",
    "            f\"IC_std: {ind.fitness.values[1]}, \"\n",
    "            f\"ICIR: {ind.fitness.values[0] / ind.fitness.values[1] if ind.fitness.values[1] != 0 else np.nan}, \"\n",
    "            f\"空值个数: {ind.fitness.values[2]}, \"\n",
    "            f\"复杂度: {ind.fitness.values[3]},\"\n",
    "        )\n",
    "\n",
    "    return best_individuals, [ind.fitness.values for ind in best_individuals], population, hall_of_fame, hof_importance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
